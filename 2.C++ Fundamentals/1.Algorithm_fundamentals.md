# Algorithm Fundamentals
The word Algorithm means "A set of rules to be followed in calculations or other problem-solving operations" or, more simply "a finite steps of instructions to solve a problem".

## Algorithms, the basics
Algorithms normally represented in one of the three ways:

    • pseudo-code
    • flowchart
    • structured Natural language
Algorithms can be assessed based on time complexity and space complexity

    • Time complexity is the measure of how much time an algorithm needed 
    • Space complexity is the measure of how much space an algorithm needed

## Recursive algorithms
Recursive algorithms have the following characteristics: 

    • A recursive algorithm must have a base case to allow it to terminate/return.
    • A recursive algorithm must change its state and move toward the base case.
    • A recursive algorithm must call itself, recursively. 
Recursive algorithms are for solving problems of recursive nature. An example of a recursive problem is the factorial calculation of an integer N, for example: 
4!= 4 x 3 x 2 x 1 
the base case is when the number is 1, 1!=1. (0! = 1 as well!), the recursion lies in the fact that N! = N x (N-1)! = N x (N-1) X (N-2)! so on and so further

## The Big-O notation
Big-O notation is a way of measure the time complexity of algorithms. As time requirement is closely related to number of operations, this is normally measured in the number of operations, thus the O in Big-O. It is important to understand that Big-O notation is a measure on how the time will grow as the number of data input grow. Big-O provides the worst case measure for time.

### Constant Time Function - O(1)
This notation means an algorithm has the time complexity of a constant - regardless of the growth of data input size, the algorithm will take the same amount of time. 
An example: access an item in a dictionary (hash-table) will take the same time regardless how big the dictionary is. Another example will be when checking if a number is even or odd by using the modular operation.

### Logarithmic Time Function - O(log N)
This notation means an algorithm will increase its time by 1 when its input size doubled. 
An example: binary search. As shown in the following figure, even  the array size has doubled(right hand side), there is only one more  comparison added.

### Linear Time Function - O(N)
This notation means an algorithm has the time complexity of a linear function - as the data input size grows, the algorithm will take the amount of time that is directly proportionate to the input size.
An example: linear search (remember Big-O is for the worst case) as the number of items increases, so is the number of comparisons.

### Polynomial Time Function - O(N2)
This notation means as the data input size increases, the time required will be squared.
An example: bubble sort where as the number of items increases, the worst case number of operations will be square of the number of items.

### Exponential Time Function - O(2N)
This notation means for every added input item, the time required will be doubled.
This time complexity is for intractable problems which are problems cannot be solved using polynomial time or less. The algorithms for this type problems are not optimal for computers to run in a reasonable amount time to be useful. 
An example: the traveling salesman problem(TSP) where a salesman has to visit N towns. Each pair of towns is joined by a route of a given length. Find the shortest possible route that visits all the towns and returns to the starting point. The time increases exponentially for large N.